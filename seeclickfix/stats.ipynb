{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1500, 43)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# SET PARAMETERS FOR ANALYSIS AND LOAD DATA\n",
    "\n",
    "# configure your own bounds for analysis; week start and end reflect Sunday - Saturday\n",
    "config = {\n",
    "    'week_start': '03-05-2017',\n",
    "    'week_end': '03-11-2017',\n",
    "    'import_path': '/Users/jessicamcinchak/Downloads/weekly_scf_issues.csv',\n",
    "    'export_path': 'metrics.csv',\n",
    "    'print_stacked': False\n",
    "}\n",
    "\n",
    "# dict of Service Level Agreements by type with days committed to close\n",
    "sla_days_to_close = {\n",
    "    'Abandoned Vehicle': 5,\n",
    "    'Illegal Dumping / Illegal Dump Sites': 10,\n",
    "    'Tree Issue': 14,\n",
    "    'Potholes': 5,\n",
    "    'Residential Snow Removal Issue': 1,\n",
    "    'Traffic Signal Issue': 14,\n",
    "    'Traffic Sign Issue': 7,\n",
    "    'Street Light Pole Down': 2,\n",
    "    'New LED Street Light Out': 7,\n",
    "    'Dead Animal Removal': 3,\n",
    "    'Curbside Solid Waste Issue': 7,\n",
    "    'Running Water in a Home or Building': 1,\n",
    "    'Water Main Break': 1,\n",
    "    'Fire Hydrant Issue': 1,\n",
    "    'Manhole Cover Issue': 1,\n",
    "    'Blocked Catch Basin': 1,\n",
    "    'DPW - Debris Removal - DPW USE ONLY': 0,\n",
    "    'DPW - Other environmental': 0,\n",
    "    'Park Issue': 0 \n",
    "}\n",
    "\n",
    "# transform the SLA dict to a dataframe\n",
    "sla_df = pd.DataFrame(list(sla_days_to_close.items()), columns=['request_type_title', 'sla_days_to_close'])\n",
    "\n",
    "# import the SeeClickFix issues csv as a dataframe\n",
    "scf_df = pd.read_csv(config['import_path'], low_memory=False)\n",
    "\n",
    "# set better console display\n",
    "pd.set_option('display.expand_frame_repr', False)\n",
    "\n",
    "# check that the dimensions (rows, cols) of our dataframe are as expected\n",
    "print(scf_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1500, 49)\n"
     ]
    }
   ],
   "source": [
    "# CLEAN UP THE DEFAULT SCF DATA FORMATS AND CREATE SOME NEW COLUMNS FOR SIMPLER ANALYSIS\n",
    "\n",
    "# HELPER FUNCTIONS\n",
    "\n",
    "# reformats object as mm-dd-yyyy\n",
    "def simpleDate(obj):\n",
    "    return datetime.strptime(obj[:-6], '%Y-%m-%dT%H:%M:%S').strftime('%m-%d-%Y')\n",
    "\n",
    "# converts object into specific datetime object type '<M8[ns]'\n",
    "def makeDateObj(obj):\n",
    "    return datetime.strptime(obj[:-6], '%Y-%m-%dT%H:%M:%S')\n",
    "\n",
    "# converts a timedelta to a float (eg '2 days 12:00:00' becomes '2.5')\n",
    "def makeFloat(td):\n",
    "    return td.total_seconds() / timedelta (days=1).total_seconds()\n",
    "\n",
    "# check if issues were closed within their SLA; returns 1 if yes/under, 0 if no/over, or NaN if not yet closed\n",
    "def slaCheck(row):\n",
    "    if (row['days_create_to_close'] > 0):\n",
    "        if row['days_create_to_close'] < sla_days_to_close[row['request_type_title']]:\n",
    "            return 1\n",
    "        return 0\n",
    "    pass\n",
    "\n",
    "# NEW COLUMNS\n",
    "\n",
    "# add new column with simplified date, use to match config start and end\n",
    "scf_df['created_at_simple'] = scf_df['created_at'].apply(lambda x: simpleDate(x))\n",
    "\n",
    "# add new columns with datetime object, so we can do math on them\n",
    "scf_df['created_at_obj'] = scf_df['created_at'].apply(lambda x: makeDateObj(x))\n",
    "# only do this where closed_at is not nan\n",
    "scf_df['closed_at_obj'] = scf_df['closed_at'].apply(lambda x: makeDateObj(x) if(pd.notnull(x)) else x)\n",
    "\n",
    "# add new column with diff value, returns timedelta or NaT if the issue is not closed yet\n",
    "scf_df['diff_create_to_close'] = scf_df['closed_at_obj'] - scf_df['created_at_obj']\n",
    "\n",
    "# add new column with float (fractional days), so we can calculate median\n",
    "scf_df['days_create_to_close'] = scf_df['diff_create_to_close'].apply(lambda x: makeFloat(x))\n",
    "\n",
    "# add new column for indicating whether a closed issue is under or over its SLA\n",
    "scf_df['within_sla_bool'] = scf_df.apply(lambda row: slaCheck(row), axis=1)\n",
    "\n",
    "# check that we successfully added 6 new cols\n",
    "print(scf_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1027, 49)\n"
     ]
    }
   ],
   "source": [
    "# FILTER THE FULL DATAFRAME BY THE TIME PARAMETERS WE SET\n",
    "\n",
    "# convert object into datetime object\n",
    "def convertStringToDate(obj):\n",
    "    return datetime.strptime(obj, '%m-%d-%Y')\n",
    "\n",
    "# store datetime values\n",
    "a = scf_df['created_at_simple'].apply(lambda x: convertStringToDate(x))\n",
    "b = convertStringToDate(config['week_start'])\n",
    "c = convertStringToDate(config['week_end'])\n",
    "\n",
    "# store datetime comparisons as bools\n",
    "# filter for: start <= created_at_simple <= end\n",
    "start = b <= a\n",
    "end = a <= c\n",
    "\n",
    "# filter all issues by configurable start and end dates, set as new dataframe\n",
    "filtered_df = scf_df.loc[start & end]\n",
    "\n",
    "# check that we successfully filtered rows\n",
    "print(filtered_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stats for 1027 issues created from 03-05-2017 to 03-11-2017\n"
     ]
    }
   ],
   "source": [
    "# WEEKLY ANALYTICS START HERE\n",
    "\n",
    "print(\"\"\"Stats for {} issues created from {} to {}\"\"\".format(len(filtered_df.index), config['week_start'], config['week_end']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  request_status  number_issues\n",
      "0   Acknowledged            383\n",
      "1       Archived             17\n",
      "2         Closed            596\n",
      "3           Open             31\n"
     ]
    }
   ],
   "source": [
    "# count issues by status (as of date of data we import)\n",
    "status_count_df = filtered_df.groupby('status', as_index=False)['created_at'].count()\n",
    "status_count_df.columns = ['request_status', 'number_issues']\n",
    "print(status_count_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# count issues by type\n",
    "type_count_df = filtered_df.groupby('request_type_title', as_index=False)['created_at'].count()\n",
    "type_count_df.columns = ['request_type_title', 'num_issues']\n",
    "\n",
    "# count just the ones that have been closed (this is the denominator for median_days_create_to_close)\n",
    "type_closed_count_df = filtered_df.groupby('request_type_title', as_index=False)['closed_at'].count()\n",
    "type_closed_count_df.columns = ['request_type_title', 'num_closed']\n",
    "\n",
    "# merge and display as single dataframe\n",
    "volume_df = pd.merge(type_count_df, type_closed_count_df, on='request_type_title', how='outer')\n",
    "# print(volume_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      request_type_title  median_days_create_to_close  sla_days_to_close\n",
      "0                      Abandoned Vehicle                     1.830208                  5\n",
      "1                    Blocked Catch Basin                          NaN                  1\n",
      "2             Curbside Solid Waste Issue                     2.085995                  7\n",
      "3    DPW - Debris Removal - DPW USE ONLY                     6.833490                  0\n",
      "4              DPW - Other environmental                     1.258438                  0\n",
      "5                    Dead Animal Removal                     0.000475                  3\n",
      "6                     Fire Hydrant Issue                          NaN                  1\n",
      "7   Illegal Dumping / Illegal Dump Sites                     2.105185                 10\n",
      "8                    Manhole Cover Issue                     0.420816                  1\n",
      "9               New LED Street Light Out                     1.753183                  7\n",
      "10                            Park Issue                          NaN                  0\n",
      "11                              Potholes                     0.828316                  5\n",
      "12   Running Water in a Home or Building                     0.713299                  1\n",
      "13                Street Light Pole Down                     0.841655                  2\n",
      "14                    Traffic Sign Issue                     4.604525                  7\n",
      "15                  Traffic Signal Issue                     0.303160                 14\n",
      "16                            Tree Issue                     2.080579                 14\n",
      "17                      Water Main Break                     0.531273                  1\n",
      "18        Residential Snow Removal Issue                          NaN                  1\n"
     ]
    }
   ],
   "source": [
    "# calculate median days from create to close for closed issues by type\n",
    "med_type_df = filtered_df.groupby('request_type_title', as_index=False)['days_create_to_close'].median()\n",
    "med_type_df.columns = ['request_type_title', 'median_days_create_to_close']\n",
    "\n",
    "# compare to SLAs for each type, merge and display as single dataframe\n",
    "days_compare_df = pd.merge(med_type_df, sla_df, on='request_type_title', how='outer')\n",
    "print(days_compare_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      request_type_title  num_issues  num_closed  num_within_sla  perc_within_sla\n",
      "0                      Abandoned Vehicle          57          26            26.0       100.000000\n",
      "1                    Blocked Catch Basin          36           0             NaN              NaN\n",
      "2             Curbside Solid Waste Issue          81          59            57.0        96.610169\n",
      "3    DPW - Debris Removal - DPW USE ONLY          75          14             0.0         0.000000\n",
      "4              DPW - Other environmental         108          85             0.0         0.000000\n",
      "5                    Dead Animal Removal          29          29            29.0       100.000000\n",
      "6                     Fire Hydrant Issue           5           0             NaN              NaN\n",
      "7   Illegal Dumping / Illegal Dump Sites         102          62            62.0       100.000000\n",
      "8                    Manhole Cover Issue          10           4             3.0        75.000000\n",
      "9               New LED Street Light Out          34          21            21.0       100.000000\n",
      "10                            Park Issue           1           0             NaN              NaN\n",
      "11                              Potholes          93          80            80.0       100.000000\n",
      "12   Running Water in a Home or Building          22          16             9.0        56.250000\n",
      "13                Street Light Pole Down           9           9             9.0       100.000000\n",
      "14                    Traffic Sign Issue          41          19            19.0       100.000000\n",
      "15                  Traffic Signal Issue          40          29            29.0       100.000000\n",
      "16                            Tree Issue         258         137           137.0       100.000000\n",
      "17                      Water Main Break          26           9             6.0        66.666667\n"
     ]
    }
   ],
   "source": [
    "# calculate number of issues by type that were closed within their SLA\n",
    "num_sla_df = filtered_df.groupby('request_type_title', as_index=False)['within_sla_bool'].sum()\n",
    "num_sla_df.columns = ['request_type_title', 'num_within_sla']\n",
    "\n",
    "# merge and display as single dataframe\n",
    "sla_df = pd.merge(volume_df, num_sla_df, on='request_type_title', how='outer')\n",
    "\n",
    "# add a new column with the percent; num_within_sla divided by num_closed, times 100 for readability\n",
    "sla_df['perc_within_sla'] = (sla_df['num_within_sla'] / sla_df['num_closed']) * 100\n",
    "print(sla_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      request_type_title  num_reopened  num_canonical\n",
      "0                      Abandoned Vehicle             0              0\n",
      "1                    Blocked Catch Basin             0              2\n",
      "2             Curbside Solid Waste Issue             1              2\n",
      "3    DPW - Debris Removal - DPW USE ONLY             1              0\n",
      "4              DPW - Other environmental             0              0\n",
      "5                    Dead Animal Removal             0              0\n",
      "6                     Fire Hydrant Issue             0              0\n",
      "7   Illegal Dumping / Illegal Dump Sites             2             12\n",
      "8                    Manhole Cover Issue             0              0\n",
      "9               New LED Street Light Out             0              0\n",
      "10                            Park Issue             0              0\n",
      "11                              Potholes             6              0\n",
      "12   Running Water in a Home or Building             0              0\n",
      "13                Street Light Pole Down             1              0\n",
      "14                    Traffic Sign Issue             0              0\n",
      "15                  Traffic Signal Issue             0              0\n",
      "16                            Tree Issue             2              0\n",
      "17                      Water Main Break             0              0\n"
     ]
    }
   ],
   "source": [
    "# count issues that were reopened by type\n",
    "reopened_type_df = filtered_df.groupby('request_type_title', as_index=False)['reopened_at'].count()\n",
    "reopened_type_df.columns = ['request_type_title', 'num_reopened']\n",
    "\n",
    "# count issues that are marked as canonical (aka top-level duplicate) by type\n",
    "canonical_type_df = filtered_df.groupby('request_type_title', as_index=False)['canonical_issue_id'].count()\n",
    "canonical_type_df.columns = ['request_type_title', 'num_canonical']\n",
    "\n",
    "# merge and display as single dataframe\n",
    "num_compare_df = pd.merge(reopened_type_df, canonical_type_df, on='request_type_title', how='outer')\n",
    "print(num_compare_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# EXPORT RESULTS\n",
    "\n",
    "# merge various dataframes above into a single dataframe by type\n",
    "merge_one = pd.merge(sla_df, num_compare_df, on='request_type_title', how='outer')\n",
    "merge_all = pd.merge(merge_one, days_compare_df, on='request_type_title', how='outer')\n",
    "\n",
    "# include just the columns we care about most\n",
    "show_less = merge_all[['request_type_title', 'num_issues', 'num_closed', 'median_days_create_to_close', 'sla_days_to_close', 'perc_within_sla', 'num_reopened']]\n",
    "\n",
    "# export as csv based on configurable printing variable; prints horizontally aligned by default with headers in row one\n",
    "if config['print_stacked']:\n",
    "    show_less.stack().to_csv(config['export_path'])\n",
    "else:\n",
    "    show_less.to_csv(config['export_path'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
